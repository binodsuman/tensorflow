{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.python.framework import ops\n",
    "ops.reset_default_graph()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "n_samples = 10000\n",
    "x = np.linspace(0,10,n_samples)\n",
    "# 5 is intercept and 2 is slope here and x is input.\n",
    "# Simple Linear Regression equation\n",
    "# We have to find out 2 and 5 from linear regression algorithm.\n",
    "y = 2*x + 5 # y= A*x + b"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create two variable in tensorflow for A and b\n",
    "A = tf.Variable(tf.random_normal(shape=[1,1]))\n",
    "b = tf.Variable(tf.random_normal(shape=[1,1]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Create placeholder to take training data from X\n",
    "x_data = tf.placeholder(shape=[None,1], dtype=tf.float32)\n",
    "y_target = tf.placeholder(shape=[None,1], dtype=tf.float32)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "#Output of one layer to another in neural network\n",
    "# All(Input * weight) + bias\n",
    "model_output = tf.add(tf.multiply(x_data,A),b)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Calculate error. Square root of sum of all difference of calculated and predicted data.\n",
    "# In stead of square root, we will take half of 2 * number of input to make easy of math. Both reqult more or less are same.\n",
    "loss = tf.reduce_sum(tf.pow(model_output - y_target, 2))/(2*n_samples)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Minimize loss using Gradient Descent Optimizer\n",
    "learning_rate = 0.5\n",
    "gd = tf.train.GradientDescentOptimizer(learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "train_process = gd.minimize(loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[array([[ 0.88257933]], dtype=float32), array([[-1.38830721]], dtype=float32)]\n",
      "[array([[ 2.26744413]], dtype=float32), array([[ 3.21337938]], dtype=float32)]\n",
      "[array([[ 2.08043385]], dtype=float32), array([[ 4.47070122]], dtype=float32)]\n",
      "[array([[ 2.02332211]], dtype=float32), array([[ 4.84326267]], dtype=float32)]\n",
      "[array([[ 2.00696111]], dtype=float32), array([[ 4.95381641]], dtype=float32)]\n",
      "\n",
      "Coef after 5000 iterations  [array([[ 2.00200248]], dtype=float32), array([[ 4.98645544]], dtype=float32)]\n"
     ]
    }
   ],
   "source": [
    "loss_info = []\n",
    "batch_size = 100 # Take 100 data from above x and calculate loss\n",
    "with tf.Session() as sess:\n",
    "    sess.run(A.initializer)\n",
    "    sess.run(b.initializer)\n",
    "    # we want to do this exercise 5000 times. Means each time they will take 100 data from x and y and calculate loss\n",
    "    # and adjust A and b accordingly.\n",
    "    for i in range(5000):\n",
    "        #returns randome indices from entire lot of X.\n",
    "        rand_index = np.random.choice(len(x),batch_size)\n",
    "        rand_x = x[rand_index]\n",
    "        rand_y = y[rand_index]\n",
    "        sess.run(train_process, feed_dict = {x_data: np.transpose([rand_x]), y_target: np.transpose([rand_y])})\n",
    "        loss_info.append(sess.run(loss, feed_dict = {x_data: np.transpose([rand_x]), y_target: np.transpose([rand_y])}))\n",
    "        if i % 1000 == 0:\n",
    "            print (sess.run([A,b]))\n",
    "    tf.summary.FileWriter('tensorboard/linear_regression.logs',sess.graph)\n",
    "    print('\\nCoef after 5000 iterations ',sess.run([A,b]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.78286153,\n",
       " 0.54828107,\n",
       " 0.38401815,\n",
       " 0.28082082,\n",
       " 0.20821247,\n",
       " 0.16545689,\n",
       " 0.12900712,\n",
       " 0.10018875,\n",
       " 0.086916231,\n",
       " 0.078024812,\n",
       " 0.063029341,\n",
       " 0.055527728,\n",
       " 0.049925782,\n",
       " 0.046529386,\n",
       " 0.044709869,\n",
       " 0.052552793,\n",
       " 0.041282639,\n",
       " 0.048402499,\n",
       " 0.042517941,\n",
       " 0.038415961,\n",
       " 0.047678787,\n",
       " 0.040635746,\n",
       " 0.047547869,\n",
       " 0.042810306,\n",
       " 0.044927847,\n",
       " 0.045957588,\n",
       " 0.043340202,\n",
       " 0.04412866,\n",
       " 0.044688664,\n",
       " 0.045615055,\n",
       " 0.037707269,\n",
       " 0.043025538,\n",
       " 0.040274423,\n",
       " 0.045654535,\n",
       " 0.047275413,\n",
       " 0.042676922,\n",
       " 0.038972061,\n",
       " 0.040664021,\n",
       " 0.040775537,\n",
       " 0.040238008,\n",
       " 0.041704774,\n",
       " 0.037437528,\n",
       " 0.040793438,\n",
       " 0.04275373,\n",
       " 0.042700093,\n",
       " 0.033812497,\n",
       " 0.040207602,\n",
       " 0.041976549,\n",
       " 0.045204341,\n",
       " 0.042248759,\n",
       " 0.042431336,\n",
       " 0.036093146,\n",
       " 0.039813478,\n",
       " 0.035145402,\n",
       " 0.042159732,\n",
       " 0.035499975,\n",
       " 0.043965526,\n",
       " 0.03504125,\n",
       " 0.044220638,\n",
       " 0.04610293,\n",
       " 0.034718253,\n",
       " 0.040383518,\n",
       " 0.041579206,\n",
       " 0.037850276,\n",
       " 0.04258801,\n",
       " 0.031396214,\n",
       " 0.036045223,\n",
       " 0.033415377,\n",
       " 0.043430027,\n",
       " 0.038199596,\n",
       " 0.045727994,\n",
       " 0.036987446,\n",
       " 0.041936707,\n",
       " 0.035086967,\n",
       " 0.037307337,\n",
       " 0.041012608,\n",
       " 0.031807251,\n",
       " 0.042973939,\n",
       " 0.041077361,\n",
       " 0.045204248,\n",
       " 0.035951048,\n",
       " 0.036678459,\n",
       " 0.038902372,\n",
       " 0.040640261,\n",
       " 0.049487926,\n",
       " 0.041298296,\n",
       " 0.031737115,\n",
       " 0.034313433,\n",
       " 0.037033565,\n",
       " 0.036156356,\n",
       " 0.040021062,\n",
       " 0.0418952,\n",
       " 0.0376577,\n",
       " 0.035642132,\n",
       " 0.034593958,\n",
       " 0.038960569,\n",
       " 0.033655182,\n",
       " 0.033969495,\n",
       " 0.037690789,\n",
       " 0.03884444,\n",
       " 0.037728205,\n",
       " 0.031831093,\n",
       " 0.037574213,\n",
       " 0.03445119,\n",
       " 0.038376652,\n",
       " 0.049421672,\n",
       " 0.038329534,\n",
       " 0.031211425,\n",
       " 0.038120903,\n",
       " 0.031481083,\n",
       " 0.029464724,\n",
       " 0.037761487,\n",
       " 0.030846689,\n",
       " 0.036844634,\n",
       " 0.038404197,\n",
       " 0.036362156,\n",
       " 0.033781186,\n",
       " 0.033829171,\n",
       " 0.029698877,\n",
       " 0.036391903,\n",
       " 0.038468514,\n",
       " 0.02844975,\n",
       " 0.035631418,\n",
       " 0.027613992,\n",
       " 0.031743694,\n",
       " 0.034827817,\n",
       " 0.041498337,\n",
       " 0.031078771,\n",
       " 0.038394846,\n",
       " 0.031217171,\n",
       " 0.028601827,\n",
       " 0.03641028,\n",
       " 0.033014059,\n",
       " 0.030572182,\n",
       " 0.033441197,\n",
       " 0.035174184,\n",
       " 0.030143637,\n",
       " 0.030226277,\n",
       " 0.032857552,\n",
       " 0.037097342,\n",
       " 0.036372624,\n",
       " 0.032865949,\n",
       " 0.02796185,\n",
       " 0.035809003,\n",
       " 0.034103379,\n",
       " 0.028583437,\n",
       " 0.030488888,\n",
       " 0.029546587,\n",
       " 0.035280164,\n",
       " 0.032564454,\n",
       " 0.036220133,\n",
       " 0.029916214,\n",
       " 0.034898069,\n",
       " 0.028589962,\n",
       " 0.03338575,\n",
       " 0.029428082,\n",
       " 0.032973994,\n",
       " 0.02988572,\n",
       " 0.03275669,\n",
       " 0.027709765,\n",
       " 0.030612154,\n",
       " 0.034488004,\n",
       " 0.028044973,\n",
       " 0.031264305,\n",
       " 0.025727568,\n",
       " 0.028920494,\n",
       " 0.027400287,\n",
       " 0.029713109,\n",
       " 0.029614037,\n",
       " 0.029411737,\n",
       " 0.031798232,\n",
       " 0.031570852,\n",
       " 0.037345029,\n",
       " 0.031781603,\n",
       " 0.027934972,\n",
       " 0.032420356,\n",
       " 0.025397819,\n",
       " 0.024137489,\n",
       " 0.031430546,\n",
       " 0.027984578,\n",
       " 0.032591157,\n",
       " 0.028704375,\n",
       " 0.023712849,\n",
       " 0.031101037,\n",
       " 0.02992527,\n",
       " 0.032032337,\n",
       " 0.026718065,\n",
       " 0.027228061,\n",
       " 0.029575171,\n",
       " 0.029503958,\n",
       " 0.032346226,\n",
       " 0.033885133,\n",
       " 0.025579546,\n",
       " 0.028156104,\n",
       " 0.024561865,\n",
       " 0.031935554,\n",
       " 0.027699612,\n",
       " 0.026626196,\n",
       " 0.022892296,\n",
       " 0.029380269,\n",
       " 0.035436854,\n",
       " 0.032662336,\n",
       " 0.030737322,\n",
       " 0.03288693,\n",
       " 0.031759292,\n",
       " 0.027902298,\n",
       " 0.033038173,\n",
       " 0.025806084,\n",
       " 0.027015176,\n",
       " 0.026671151,\n",
       " 0.030242246,\n",
       " 0.029414084,\n",
       " 0.023044905,\n",
       " 0.029798763,\n",
       " 0.027635515,\n",
       " 0.024804141,\n",
       " 0.030250575,\n",
       " 0.025137095,\n",
       " 0.026163843,\n",
       " 0.026307411,\n",
       " 0.022621578,\n",
       " 0.028007824,\n",
       " 0.02739949,\n",
       " 0.026723467,\n",
       " 0.022925522,\n",
       " 0.029332763,\n",
       " 0.033617329,\n",
       " 0.023757638,\n",
       " 0.026506674,\n",
       " 0.027975092,\n",
       " 0.021044441,\n",
       " 0.027444955,\n",
       " 0.021817582,\n",
       " 0.024731569,\n",
       " 0.027258366,\n",
       " 0.027138021,\n",
       " 0.026223065,\n",
       " 0.023948886,\n",
       " 0.029065801,\n",
       " 0.024347043,\n",
       " 0.026219109,\n",
       " 0.025426541,\n",
       " 0.025338631,\n",
       " 0.022713829,\n",
       " 0.025953252,\n",
       " 0.023142004,\n",
       " 0.021916248,\n",
       " 0.023776475,\n",
       " 0.025187869,\n",
       " 0.025546987,\n",
       " 0.023577625,\n",
       " 0.02602247,\n",
       " 0.023672519,\n",
       " 0.025631869,\n",
       " 0.022840409,\n",
       " 0.020558979,\n",
       " 0.02710297,\n",
       " 0.021476248,\n",
       " 0.029297616,\n",
       " 0.027945748,\n",
       " 0.028888671,\n",
       " 0.020748267,\n",
       " 0.024501851,\n",
       " 0.024850357,\n",
       " 0.026542388,\n",
       " 0.023727097,\n",
       " 0.029940249,\n",
       " 0.021100447,\n",
       " 0.022299843,\n",
       " 0.023953229,\n",
       " 0.024641864,\n",
       " 0.023901235,\n",
       " 0.023926709,\n",
       " 0.022654155,\n",
       " 0.02645386,\n",
       " 0.021993184,\n",
       " 0.019803444,\n",
       " 0.019493446,\n",
       " 0.023011994,\n",
       " 0.027891772,\n",
       " 0.021967817,\n",
       " 0.027437001,\n",
       " 0.020102572,\n",
       " 0.026536889,\n",
       " 0.026978496,\n",
       " 0.028113686,\n",
       " 0.023823798,\n",
       " 0.02443062,\n",
       " 0.024840448,\n",
       " 0.0210099,\n",
       " 0.024732092,\n",
       " 0.019256119,\n",
       " 0.021942882,\n",
       " 0.019148853,\n",
       " 0.025374617,\n",
       " 0.021467844,\n",
       " 0.022791237,\n",
       " 0.021026934,\n",
       " 0.023201285,\n",
       " 0.02176963,\n",
       " 0.020563243,\n",
       " 0.024373524,\n",
       " 0.024734788,\n",
       " 0.022249971,\n",
       " 0.022193421,\n",
       " 0.02613586,\n",
       " 0.018853847,\n",
       " 0.017354017,\n",
       " 0.019681126,\n",
       " 0.021157302,\n",
       " 0.023193551,\n",
       " 0.021198068,\n",
       " 0.01955997,\n",
       " 0.023578577,\n",
       " 0.021317279,\n",
       " 0.019367423,\n",
       " 0.020327797,\n",
       " 0.021276753,\n",
       " 0.019581949,\n",
       " 0.020321695,\n",
       " 0.023812806,\n",
       " 0.021414381,\n",
       " 0.021282636,\n",
       " 0.021203684,\n",
       " 0.025560869,\n",
       " 0.019410975,\n",
       " 0.021240419,\n",
       " 0.01817088,\n",
       " 0.025061533,\n",
       " 0.018060349,\n",
       " 0.020237118,\n",
       " 0.016977649,\n",
       " 0.022779634,\n",
       " 0.023321753,\n",
       " 0.021096935,\n",
       " 0.020402404,\n",
       " 0.016873766,\n",
       " 0.016764401,\n",
       " 0.019061472,\n",
       " 0.026433617,\n",
       " 0.017158123,\n",
       " 0.020364707,\n",
       " 0.020598371,\n",
       " 0.021596624,\n",
       " 0.023485608,\n",
       " 0.014938958,\n",
       " 0.020362062,\n",
       " 0.015549462,\n",
       " 0.020396514,\n",
       " 0.019481227,\n",
       " 0.019649895,\n",
       " 0.018863186,\n",
       " 0.021696545,\n",
       " 0.017318921,\n",
       " 0.020770499,\n",
       " 0.020034745,\n",
       " 0.021616608,\n",
       " 0.016841063,\n",
       " 0.018327028,\n",
       " 0.015161797,\n",
       " 0.016998477,\n",
       " 0.02158018,\n",
       " 0.017439278,\n",
       " 0.017785667,\n",
       " 0.021341065,\n",
       " 0.018205097,\n",
       " 0.020100949,\n",
       " 0.0198799,\n",
       " 0.018395247,\n",
       " 0.017696591,\n",
       " 0.015318226,\n",
       " 0.018674057,\n",
       " 0.022031216,\n",
       " 0.020008115,\n",
       " 0.012087468,\n",
       " 0.014851676,\n",
       " 0.022617828,\n",
       " 0.018381888,\n",
       " 0.02165108,\n",
       " 0.018169958,\n",
       " 0.01726081,\n",
       " 0.017286787,\n",
       " 0.016672129,\n",
       " 0.021133298,\n",
       " 0.017960221,\n",
       " 0.017630473,\n",
       " 0.021750508,\n",
       " 0.014941443,\n",
       " 0.018684113,\n",
       " 0.020810364,\n",
       " 0.017390914,\n",
       " 0.017517576,\n",
       " 0.018460115,\n",
       " 0.019256121,\n",
       " 0.021458395,\n",
       " 0.019614659,\n",
       " 0.016667198,\n",
       " 0.016632177,\n",
       " 0.017146038,\n",
       " 0.017078873,\n",
       " 0.020527462,\n",
       " 0.01410624,\n",
       " 0.017543439,\n",
       " 0.017494336,\n",
       " 0.016851343,\n",
       " 0.01823361,\n",
       " 0.018203283,\n",
       " 0.017565148,\n",
       " 0.017674426,\n",
       " 0.014133172,\n",
       " 0.016060442,\n",
       " 0.01780301,\n",
       " 0.018804042,\n",
       " 0.017831651,\n",
       " 0.016570656,\n",
       " 0.01832089,\n",
       " 0.016029654,\n",
       " 0.014915995,\n",
       " 0.015857225,\n",
       " 0.014657016,\n",
       " 0.016065018,\n",
       " 0.018955356,\n",
       " 0.021320255,\n",
       " 0.021128414,\n",
       " 0.016636061,\n",
       " 0.018155044,\n",
       " 0.017533548,\n",
       " 0.016107138,\n",
       " 0.016113797,\n",
       " 0.018035771,\n",
       " 0.016222969,\n",
       " 0.013489343,\n",
       " 0.01749056,\n",
       " 0.014603768,\n",
       " 0.016256208,\n",
       " 0.015697334,\n",
       " 0.014983314,\n",
       " 0.016310422,\n",
       " 0.010185175,\n",
       " 0.012970977,\n",
       " 0.015258431,\n",
       " 0.012877319,\n",
       " 0.01620589,\n",
       " 0.016867165,\n",
       " 0.017008029,\n",
       " 0.015951382,\n",
       " 0.014718654,\n",
       " 0.017509334,\n",
       " 0.019254055,\n",
       " 0.017118212,\n",
       " 0.016336609,\n",
       " 0.014074243,\n",
       " 0.01845503,\n",
       " 0.013892093,\n",
       " 0.015414947,\n",
       " 0.013776277,\n",
       " 0.013182339,\n",
       " 0.016285453,\n",
       " 0.013167028,\n",
       " 0.013174487,\n",
       " 0.015286657,\n",
       " 0.013375035,\n",
       " 0.013544705,\n",
       " 0.017198082,\n",
       " 0.014102073,\n",
       " 0.015951438,\n",
       " 0.01324027,\n",
       " 0.016358076,\n",
       " 0.013749814,\n",
       " 0.014984526,\n",
       " 0.0167599,\n",
       " 0.016198026,\n",
       " 0.015460356,\n",
       " 0.01461985,\n",
       " 0.014255925,\n",
       " 0.01421015,\n",
       " 0.014149852,\n",
       " 0.012858626,\n",
       " 0.013197802,\n",
       " 0.011795019,\n",
       " 0.01204216,\n",
       " 0.013720267,\n",
       " 0.015562811,\n",
       " 0.014370859,\n",
       " 0.014251858,\n",
       " 0.013720295,\n",
       " 0.012204099,\n",
       " 0.014062239,\n",
       " 0.0140644,\n",
       " 0.015249779,\n",
       " 0.01332556,\n",
       " 0.016221588,\n",
       " 0.012233376,\n",
       " 0.014014581,\n",
       " 0.012544754,\n",
       " 0.013663837,\n",
       " 0.01592686,\n",
       " 0.014531701,\n",
       " 0.013063211,\n",
       " 0.012631146,\n",
       " 0.011788987,\n",
       " 0.012261161,\n",
       " 0.011389296,\n",
       " 0.012850095,\n",
       " 0.01083979,\n",
       " 0.015165782,\n",
       " 0.012760811,\n",
       " 0.01420774,\n",
       " 0.013675757,\n",
       " 0.013700962,\n",
       " 0.012757014,\n",
       " 0.013991687,\n",
       " 0.012879478,\n",
       " 0.012313694,\n",
       " 0.011735301,\n",
       " 0.013407192,\n",
       " 0.012351908,\n",
       " 0.011195879,\n",
       " 0.012010272,\n",
       " 0.014733466,\n",
       " 0.015587712,\n",
       " 0.013457687,\n",
       " 0.012973528,\n",
       " 0.01297685,\n",
       " 0.013914659,\n",
       " 0.014444937,\n",
       " 0.011837411,\n",
       " 0.011803303,\n",
       " 0.011149276,\n",
       " 0.01132963,\n",
       " 0.012978471,\n",
       " 0.012654566,\n",
       " 0.011324241,\n",
       " 0.015242541,\n",
       " 0.012307649,\n",
       " 0.011775015,\n",
       " 0.010865921,\n",
       " 0.014273362,\n",
       " 0.011448891,\n",
       " 0.012725379,\n",
       " 0.012586078,\n",
       " 0.011172497,\n",
       " 0.013236386,\n",
       " 0.012786438,\n",
       " 0.012290526,\n",
       " 0.011743679,\n",
       " 0.01289855,\n",
       " 0.011322364,\n",
       " 0.012096616,\n",
       " 0.012124743,\n",
       " 0.0098237973,\n",
       " 0.013331454,\n",
       " 0.010840514,\n",
       " 0.011200025,\n",
       " 0.012361356,\n",
       " 0.01197626,\n",
       " 0.011038195,\n",
       " 0.011442043,\n",
       " 0.010453415,\n",
       " 0.012240879,\n",
       " 0.012373254,\n",
       " 0.011991313,\n",
       " 0.01217594,\n",
       " 0.014067511,\n",
       " 0.012170045,\n",
       " 0.012299769,\n",
       " 0.012342683,\n",
       " 0.010568109,\n",
       " 0.0098502059,\n",
       " 0.013525072,\n",
       " 0.011922537,\n",
       " 0.011692457,\n",
       " 0.011400728,\n",
       " 0.011652535,\n",
       " 0.010474545,\n",
       " 0.0099527948,\n",
       " 0.010982223,\n",
       " 0.012642893,\n",
       " 0.0098383203,\n",
       " 0.011551828,\n",
       " 0.0099256868,\n",
       " 0.0098859463,\n",
       " 0.0097830603,\n",
       " 0.012908262,\n",
       " 0.0094520915,\n",
       " 0.0098881284,\n",
       " 0.0088632694,\n",
       " 0.010897666,\n",
       " 0.014794683,\n",
       " 0.011682891,\n",
       " 0.011685295,\n",
       " 0.010501787,\n",
       " 0.011581464,\n",
       " 0.011715353,\n",
       " 0.011462495,\n",
       " 0.00999262,\n",
       " 0.011648778,\n",
       " 0.009613418,\n",
       " 0.010522708,\n",
       " 0.011471583,\n",
       " 0.011050267,\n",
       " 0.0096091414,\n",
       " 0.010618994,\n",
       " 0.010079354,\n",
       " 0.0097784884,\n",
       " 0.009027997,\n",
       " 0.0097001391,\n",
       " 0.010081901,\n",
       " 0.011060239,\n",
       " 0.010689778,\n",
       " 0.012343025,\n",
       " 0.0086236661,\n",
       " 0.010713256,\n",
       " 0.010455207,\n",
       " 0.010600526,\n",
       " 0.0096957795,\n",
       " 0.010413234,\n",
       " 0.010133095,\n",
       " 0.010932243,\n",
       " 0.01295432,\n",
       " 0.010185182,\n",
       " 0.0091169374,\n",
       " 0.009728468,\n",
       " 0.011019271,\n",
       " 0.011324045,\n",
       " 0.0085836602,\n",
       " 0.010100485,\n",
       " 0.0089723477,\n",
       " 0.0114176,\n",
       " 0.0099553671,\n",
       " 0.010304338,\n",
       " 0.0099059613,\n",
       " 0.0095865419,\n",
       " 0.010493309,\n",
       " 0.0098610725,\n",
       " 0.0085965572,\n",
       " 0.011280119,\n",
       " 0.0089530312,\n",
       " 0.0089320308,\n",
       " 0.0097746393,\n",
       " 0.0097174197,\n",
       " 0.0093274917,\n",
       " 0.0095589692,\n",
       " 0.010568378,\n",
       " 0.0095282868,\n",
       " 0.0095953196,\n",
       " 0.0096924752,\n",
       " 0.011021894,\n",
       " 0.011600396,\n",
       " 0.010013977,\n",
       " 0.0078027463,\n",
       " 0.0098719969,\n",
       " 0.0072265938,\n",
       " 0.0092139756,\n",
       " 0.0075682988,\n",
       " 0.0089542968,\n",
       " 0.010251879,\n",
       " 0.0084413737,\n",
       " 0.010709943,\n",
       " 0.00873964,\n",
       " 0.0083791651,\n",
       " 0.0095834127,\n",
       " 0.0094452053,\n",
       " 0.0074528824,\n",
       " 0.0088865533,\n",
       " 0.008121795,\n",
       " 0.0077933124,\n",
       " 0.0093687577,\n",
       " 0.009769368,\n",
       " 0.0093084732,\n",
       " 0.0080645932,\n",
       " 0.0076153954,\n",
       " 0.008798549,\n",
       " 0.0096326768,\n",
       " 0.0075421445,\n",
       " 0.0081696697,\n",
       " 0.0092092212,\n",
       " 0.0083389804,\n",
       " 0.0071917423,\n",
       " 0.0089779831,\n",
       " 0.0086940797,\n",
       " 0.0081048906,\n",
       " 0.0079778098,\n",
       " 0.0090634804,\n",
       " 0.0086929994,\n",
       " 0.0082480758,\n",
       " 0.0083278818,\n",
       " 0.0096381949,\n",
       " 0.0081425561,\n",
       " 0.0091075106,\n",
       " 0.0063800369,\n",
       " 0.00984246,\n",
       " 0.0082011325,\n",
       " 0.0085404841,\n",
       " 0.0078834882,\n",
       " 0.0083823381,\n",
       " 0.0084267501,\n",
       " 0.0072143204,\n",
       " 0.0076916395,\n",
       " 0.0085968263,\n",
       " 0.0069382247,\n",
       " 0.0072482792,\n",
       " 0.0082439063,\n",
       " 0.009040867,\n",
       " 0.0076296665,\n",
       " 0.0094146794,\n",
       " 0.0094853658,\n",
       " 0.0094642714,\n",
       " 0.0066153943,\n",
       " 0.0077255848,\n",
       " 0.0077979011,\n",
       " 0.0083649615,\n",
       " 0.010037099,\n",
       " 0.0083052991,\n",
       " 0.0075123752,\n",
       " 0.0090703322,\n",
       " 0.007421874,\n",
       " 0.0076152021,\n",
       " 0.0089091463,\n",
       " 0.0069351089,\n",
       " 0.0079422081,\n",
       " 0.0078528794,\n",
       " 0.0068352963,\n",
       " 0.0082631968,\n",
       " 0.0068672597,\n",
       " 0.0061691506,\n",
       " 0.0087179979,\n",
       " 0.0067689186,\n",
       " 0.0063937069,\n",
       " 0.0085780527,\n",
       " 0.0079825968,\n",
       " 0.0091827903,\n",
       " 0.006539626,\n",
       " 0.0085482709,\n",
       " 0.0078804009,\n",
       " 0.0087554613,\n",
       " 0.0059081344,\n",
       " 0.007954401,\n",
       " 0.006747501,\n",
       " 0.0078403754,\n",
       " 0.0073642773,\n",
       " 0.0078830821,\n",
       " 0.0078093307,\n",
       " 0.0075918119,\n",
       " 0.0064115692,\n",
       " 0.0077764317,\n",
       " 0.0079997517,\n",
       " 0.0070520095,\n",
       " 0.0089300126,\n",
       " 0.0075351521,\n",
       " 0.0079997042,\n",
       " 0.0073250127,\n",
       " 0.0069226073,\n",
       " 0.0078944759,\n",
       " 0.0073247165,\n",
       " 0.0064182128,\n",
       " 0.0072379499,\n",
       " 0.007996955,\n",
       " 0.0072701811,\n",
       " 0.0069207228,\n",
       " 0.0069831982,\n",
       " 0.0081353663,\n",
       " 0.0074498542,\n",
       " 0.0075558415,\n",
       " 0.006745101,\n",
       " 0.0071343826,\n",
       " 0.0081675546,\n",
       " 0.0069021331,\n",
       " 0.0069086002,\n",
       " 0.0066480194,\n",
       " 0.0080832569,\n",
       " 0.0078383926,\n",
       " 0.0081423754,\n",
       " 0.0058381855,\n",
       " 0.0067267609,\n",
       " 0.0052400525,\n",
       " 0.0072117765,\n",
       " 0.0067997421,\n",
       " 0.0068551796,\n",
       " 0.006479382,\n",
       " 0.0080525028,\n",
       " 0.0058092931,\n",
       " 0.0064871893,\n",
       " 0.0065215765,\n",
       " 0.0064109447,\n",
       " 0.006302597,\n",
       " 0.0081838099,\n",
       " 0.00557455,\n",
       " 0.0059367493,\n",
       " 0.0062976093,\n",
       " 0.0080341725,\n",
       " 0.0076320423,\n",
       " 0.0074831471,\n",
       " 0.0053956076,\n",
       " 0.0058713341,\n",
       " 0.0071221548,\n",
       " 0.0059203194,\n",
       " 0.0056533003,\n",
       " 0.0071923453,\n",
       " 0.0063559865,\n",
       " 0.0065263668,\n",
       " 0.0066131842,\n",
       " 0.0068750898,\n",
       " 0.0074186781,\n",
       " 0.0062311138,\n",
       " 0.0063675991,\n",
       " 0.0066175316,\n",
       " 0.0071639479,\n",
       " 0.0070590382,\n",
       " 0.0059876475,\n",
       " 0.0062919636,\n",
       " 0.0069232024,\n",
       " 0.0054740277,\n",
       " 0.0068839071,\n",
       " 0.0056552677,\n",
       " 0.0073156636,\n",
       " 0.0066939015,\n",
       " 0.0067718816,\n",
       " 0.0063235969,\n",
       " 0.0068284506,\n",
       " 0.0063567432,\n",
       " 0.0052231816,\n",
       " 0.00614955,\n",
       " 0.0067910086,\n",
       " 0.0066670026,\n",
       " 0.0061734989,\n",
       " 0.0059450809,\n",
       " 0.0066312519,\n",
       " 0.007111901,\n",
       " 0.0064954939,\n",
       " 0.0055999882,\n",
       " 0.0052789743,\n",
       " 0.006043022,\n",
       " 0.0064413291,\n",
       " 0.0062568467,\n",
       " 0.0063704238,\n",
       " 0.0056597013,\n",
       " 0.0052717905,\n",
       " 0.0058345124,\n",
       " 0.0064521492,\n",
       " 0.0054575093,\n",
       " 0.0073624053,\n",
       " 0.0063838782,\n",
       " 0.0063768444,\n",
       " 0.0047958703,\n",
       " 0.0057152696,\n",
       " 0.0063417298,\n",
       " 0.0064041098,\n",
       " 0.0058276341,\n",
       " 0.0061357208,\n",
       " 0.0066058906,\n",
       " 0.0055354461,\n",
       " 0.0048542446,\n",
       " 0.0059162392,\n",
       " 0.0059525738,\n",
       " 0.0038162365,\n",
       " 0.0055811293,\n",
       " 0.0059318398,\n",
       " 0.0054421052,\n",
       " 0.0058640824,\n",
       " 0.0052680532,\n",
       " 0.0054202578,\n",
       " 0.0049023544,\n",
       " 0.0046973964,\n",
       " 0.005261525,\n",
       " 0.0053271116,\n",
       " 0.0058191018,\n",
       " 0.0047654533,\n",
       " 0.0049873753,\n",
       " 0.005547951,\n",
       " 0.0057425518,\n",
       " 0.0050988067,\n",
       " 0.0057795295,\n",
       " 0.0050817281,\n",
       " 0.0067487927,\n",
       " 0.004016778,\n",
       " 0.0056972126,\n",
       " 0.0057081669,\n",
       " 0.0051862416,\n",
       " 0.0045607369,\n",
       " 0.0047443844,\n",
       " 0.0055599203,\n",
       " 0.0041204514,\n",
       " 0.0054355469,\n",
       " 0.0056180609,\n",
       " 0.0047992831,\n",
       " 0.0045728623,\n",
       " 0.0047499686,\n",
       " 0.0064271153,\n",
       " 0.0044253599,\n",
       " 0.0047624861,\n",
       " 0.0057349042,\n",
       " 0.0057161241,\n",
       " 0.0052138055,\n",
       " 0.0046798312,\n",
       " 0.0043291762,\n",
       " 0.0054401592,\n",
       " 0.0057721846,\n",
       " 0.0051014922,\n",
       " 0.0047280299,\n",
       " 0.0052337851,\n",
       " 0.0056636287,\n",
       " 0.0052001248,\n",
       " 0.0052486407,\n",
       " 0.004615318,\n",
       " 0.0047928421,\n",
       " 0.0056079072,\n",
       " 0.0050449101,\n",
       " 0.0047743279,\n",
       " 0.0041250736,\n",
       " 0.0045533469,\n",
       " 0.0047098245,\n",
       " 0.004839004,\n",
       " 0.0052280659,\n",
       " 0.0046980702,\n",
       " 0.0046288352,\n",
       " 0.0056900745,\n",
       " 0.0050900122,\n",
       " 0.004766719,\n",
       " 0.0052280533,\n",
       " 0.0042144633,\n",
       " 0.0055816239,\n",
       " 0.0046205027,\n",
       " 0.0043258271,\n",
       " 0.0041539827,\n",
       " 0.0047475062,\n",
       " 0.0038233809,\n",
       " 0.0044183242,\n",
       " 0.0055722394,\n",
       " 0.0046428605,\n",
       " 0.0041000512,\n",
       " 0.004990431,\n",
       " 0.0052078553,\n",
       " 0.0048730471,\n",
       " 0.004375448,\n",
       " 0.0045250165,\n",
       " 0.0049185706,\n",
       " 0.004496377,\n",
       " 0.0036355662,\n",
       " 0.0046131131,\n",
       " 0.0045701591,\n",
       " 0.0044855904,\n",
       " 0.0042951703,\n",
       " 0.0044223666,\n",
       " 0.0044346196,\n",
       " 0.004919101,\n",
       " 0.0043344037,\n",
       " 0.0048471969,\n",
       " 0.005176709,\n",
       " 0.0045143501,\n",
       " 0.004615217,\n",
       " 0.0047283275,\n",
       " 0.0049880124,\n",
       " 0.0047157537,\n",
       " 0.0044724653,\n",
       " 0.0041872156,\n",
       " 0.0045339735,\n",
       " 0.0043282364,\n",
       " 0.0044559827,\n",
       " 0.0034181327,\n",
       " 0.0049149678,\n",
       " 0.0047019166,\n",
       " 0.0042571607,\n",
       " 0.0039834315,\n",
       " 0.0038199695,\n",
       " 0.0047469027,\n",
       " 0.0047679679,\n",
       " 0.0047317715,\n",
       " 0.0045185005,\n",
       " 0.0036710235,\n",
       " 0.0047159852,\n",
       " 0.004507171,\n",
       " 0.0046820552,\n",
       " 0.0050372649,\n",
       " 0.004580541,\n",
       " 0.0040562977,\n",
       " 0.004648129,\n",
       " 0.0043607359,\n",
       " 0.0034138369,\n",
       " 0.0049247728,\n",
       " 0.004758236,\n",
       " 0.0047457907,\n",
       " 0.0040467414,\n",
       " 0.0041873944,\n",
       " 0.0044515585,\n",
       " 0.0036174739,\n",
       " 0.0045007798,\n",
       " 0.0038378113,\n",
       " 0.0046292027,\n",
       " 0.0041869986,\n",
       " 0.0045670229,\n",
       " 0.0041194591,\n",
       " 0.0040616379,\n",
       " 0.0046128654,\n",
       " 0.0041802125,\n",
       " 0.0044665658,\n",
       " 0.0039991946,\n",
       " 0.0041956976,\n",
       " 0.0044520912,\n",
       " 0.0038461466,\n",
       " ...]"
      ]
     },
     "execution_count": 13,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "loss_info"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.3"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
